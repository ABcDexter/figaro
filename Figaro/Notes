TO CONSIDER FOR FIRST RELEASE: Fix the use of Values()(element) and provide something for Values(elem.universe)(elem). And Expand().expand().

Subtle bug: when an observation is made, elements that use the observed element don't have their value updated. This
causes trouble with MH because these elements may never have their value updated so will always have the incorrect
value.

Should generateValue and nextRandomness take an argument or used the stored current randomness?

FOR FIRST RELEASE: Examples:
BN
Dependency net - check whether VE gets correct result
PRM
MLN
Firms
PCFG (direct and max length)
Test all with all algorithms that will work (use test tags/fixtures)

FOR FIRST RELEASE: Full header comments.

FOR FIRST RELEASE: Comments and Scaladoc.

Major comment: MCMC proposals for elements don't go to nearby elements (e.g. with continuous elements like normal),
but suggest a new random value for the element. This leads to bad proposals. We can fix this by providing a
generateNextRandomness(currentRandomness : Randomness) method which defaults to generateRandomness, and returns the
proposal probability ratio (reverse prob / forward prob).

FOR LATER: DSL for proposal schemes.

FOR LATER: Discretize: use smart scheme that adjusts size of bin to make number of entries in bin constant


COMMENT: Limitation of abstraction schemes: point and target of abstraction need to be the same type.


FOR LATER: Junction Tree

FOR LATER: Check whether VE should use arrays as much as it does.

FOR LATER: Put in @tailrec wherever relevant.

FOR LATER: Create HasRange trait and use in Values. Classes that implement HasRange will define their possible set of values.
Create Enumerable trait for types whose set of possible values can be enumerated. In DependencyNetwork, use a view
bound so it can take any type that can be implicitly converted to Enumerable.

FOR LATER: Implicitly convert tuple of two elements into Duo. Same for Trio, etc. Define _1, _2 methods on Duo, Trio.

FOR LATER: Learning (on ACACIA):
trait Difference[T] {
  def difference(T): Double
  }

trait Parameter[Estimate <: Element[Double] with Difference[Estimate]] {
  def accumulate[T](user: Element[T], distribution: Stream[(Double, T)]): Unit

  def doEstimate(): Estimate

  def reestimate(): Double = {
    val newEstimate = doEstimate()
    val difference = currentEstimate.difference(newEstimate)
    currentEstimate = newEstimate
    difference
  }

  def initialEstimate(): Element[Double]

  var currentEstimate: Element[Double] = initialEstimate()

  def args = List(currentEstimate)

  def generateValue() = currentEstimate.value
}

class Beta extends Element[Double] with Difference[Beta]

class BetaParameter extends Element[Double] with Parameter[Beta]

A training set consists of global elements (belong to all instances) and a set of training instance.
Each training instance consists of a set of conditions on global instances and a function that generates particular
instances (with their conditions).
Parameters will generally be global.
In traditional ML, everything is global and only the conditions change.
In ACACIA, the edges and their parameters are global, but the capability, capacity, and chosen variables are specific to each instance.

learn takes a training set as argument.
preprocessing:
goes through the training instances:
creates the full model for the instance
captures it
deactivates all except the globals
calls doLearn on all the captured ids

EM: (takes one time algorithm as argument)
Repeat:
Go through training instances
  Restore instance
  Identify users
  Run algorithm with all users as targets
  Pass distributions of users to accumulate method of poarameters
Call estimate method on parameters, obtaining difference and setting currentEstimate.

Universe:
capture
restore